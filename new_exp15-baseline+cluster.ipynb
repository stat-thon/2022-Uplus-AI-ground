{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367adec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 로드\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import os, random\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9478ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 28 12:14:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:1A:00.0 Off |                  Off |\n",
      "| 33%   37C    P2    60W / 260W |   1130MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     On   | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   46C    P2   105W / 260W |  21134MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:3E:00.0 Off |                  Off |\n",
      "| 33%   34C    P8    15W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:40:00.0 Off |                  Off |\n",
      "| 33%   54C    P2   205W / 260W |  48121MiB / 48601MiB |     77%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 33%   55C    P2   243W / 260W |  48122MiB / 48601MiB |     89%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 \n",
    "class cfg: \n",
    "    gpu_idx = 2\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "    top_k = 25 #############\n",
    "    seed = 42\n",
    "    neg_ratio = 100 #######\n",
    "    test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "118803c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정 \n",
    "cfg.batch_size = 256\n",
    "cfg.emb_dim = 256\n",
    "cfg.layer_dim = 512\n",
    "cfg.dropout = 0.5\n",
    "cfg.epochs = 10\n",
    "cfg.learning_rate = 0.0025\n",
    "cfg.reg_lambda = 0\n",
    "cfg.check_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2491a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정 \n",
    "def seed_everything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "seed_everything(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15057cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "data_path = './data'\n",
    "saved_path = './code/saved'\n",
    "output_path = './code/submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6111bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.read_csv(os.path.join(data_path, 'history_data.csv'), encoding='utf-8')\n",
    "profile_df = pd.read_csv(os.path.join(data_path, 'profile_data.csv'), encoding='utf-8')\n",
    "meta_df = pd.read_csv(os.path.join(data_path, 'meta_data.csv'), encoding='utf-8')\n",
    "watch_e_df = pd.read_csv(os.path.join(data_path, 'watch_e_data.csv'), encoding='utf-8')\n",
    "search_df =  pd.read_csv(os.path.join(data_path, 'search_data.csv'), encoding='utf-8')\n",
    "buy_df = pd.read_csv(os.path.join(data_path, 'buy_data.csv'), encoding='utf-8')\n",
    "meta_plus_df = pd.read_csv(os.path.join(data_path, 'meta_data_plus.csv'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e95c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "with open('clusterset.pickle', 'rb') as f:\n",
    "    cluster_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf763e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 (중복제거) \n",
    "# 참고 : drop_duplicates의 subset을 무엇으로 구성하냐에 따라서 제거되는 항목들이 다름 \n",
    "# ex) 'profile_id', 'album_id' : 중복된 시청이력 모두 제거 / 'profile_id', 'album_id', 'log_time' : 같은 시간에 시청한 이력만 제거 \n",
    "data = history_df[['profile_id', 'log_time', 'album_id']].drop_duplicates(subset=['profile_id', 'album_id', 'log_time']).sort_values(by = ['profile_id', 'log_time']).reset_index(drop = True)\n",
    "data['rating'] = 1\n",
    "\n",
    "cfg.n_users = data.profile_id.max()+1\n",
    "cfg.n_items = data.album_id.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a559d77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기: (719401, 4)\n",
      "검증 데이터 크기: (179851, 4)\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증 데이터 분리\n",
    "train, valid = train_test_split(\n",
    "    data, test_size=cfg.test_size, random_state=cfg.seed,\n",
    ")\n",
    "print('학습 데이터 크기:', train.shape)\n",
    "print('검증 데이터 크기:', valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11173f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0daaf0f63054696b173af598dd0ab2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 형태: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix 형태로 변환 \n",
    "train = train.to_numpy()\n",
    "matrix = sparse.lil_matrix((cfg.n_users, cfg.n_items))  \n",
    "for (p, _, i, r) in tqdm(train):\n",
    "    matrix[p, i] = r\n",
    "    \n",
    "train = sparse.csr_matrix(matrix)\n",
    "train = train.toarray()\n",
    "print(\"train 형태: \\n\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3bc1ccf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33033, 25917)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e165057",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = profile_df.set_index('profile_id')\n",
    "\n",
    "le = LabelEncoder()\n",
    "profile_df['sex'] = le.fit_transform(profile_df['sex'])\n",
    "profile_df['pr_interest_keyword_cd_1'] = le.fit_transform(profile_df['pr_interest_keyword_cd_1'])\n",
    "profile_df['pr_interest_keyword_cd_2'] = le.fit_transform(profile_df['pr_interest_keyword_cd_2'])\n",
    "profile_df['pr_interest_keyword_cd_3'] = le.fit_transform(profile_df['pr_interest_keyword_cd_3'])\n",
    "profile_df['ch_interest_keyword_cd_1'] = le.fit_transform(profile_df['ch_interest_keyword_cd_1'])\n",
    "profile_df['ch_interest_keyword_cd_2'] = le.fit_transform(profile_df['ch_interest_keyword_cd_2'])\n",
    "profile_df['ch_interest_keyword_cd_3'] = le.fit_transform(profile_df['ch_interest_keyword_cd_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020d3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 특징 정보 추출 \n",
    "user_features = profile_df[['age', 'sex',\n",
    "                            'pr_interest_keyword_cd_1',\n",
    "                            'pr_interest_keyword_cd_2',\n",
    "                            'pr_interest_keyword_cd_3',\n",
    "                            'ch_interest_keyword_cd_1',\n",
    "                            'ch_interest_keyword_cd_2',\n",
    "                            'ch_interest_keyword_cd_3']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162c05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.n_pr_interest_keyword_1 = profile_df['pr_interest_keyword_cd_1'].nunique()\n",
    "cfg.n_ch_interest_keyword_1 = profile_df['ch_interest_keyword_cd_1'].nunique()\n",
    "cfg.n_pr_interest_keyword_2 = profile_df['pr_interest_keyword_cd_2'].nunique()\n",
    "cfg.n_ch_interest_keyword_2 = profile_df['ch_interest_keyword_cd_2'].nunique()\n",
    "cfg.n_pr_interest_keyword_3 = profile_df['pr_interest_keyword_cd_3'].nunique()\n",
    "cfg.n_ch_interest_keyword_3 = profile_df['ch_interest_keyword_cd_3'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70d0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = meta_df.set_index('album_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9257e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['genre_large'] = le.fit_transform(meta_df['genre_large'])\n",
    "meta_df['genre_mid'] = le.fit_transform(meta_df['genre_mid'])\n",
    "meta_df['genre_small'] = le.fit_transform(meta_df['genre_small'])\n",
    "meta_df['cast_1'] = le.fit_transform(meta_df['cast_1'])\n",
    "meta_df['cast_2'] = le.fit_transform(meta_df['cast_2'])\n",
    "meta_df['cast_3'] = le.fit_transform(meta_df['cast_3'])\n",
    "meta_df['cast_4'] = le.fit_transform(meta_df['cast_4'])\n",
    "meta_df['cast_5'] = le.fit_transform(meta_df['cast_5'])\n",
    "meta_df['cast_6'] = le.fit_transform(meta_df['cast_6'])\n",
    "meta_df['cast_7'] = le.fit_transform(meta_df['cast_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b507e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = meta_df[['genre_large', 'genre_mid', 'genre_small',\n",
    "                         'cast_1', 'cast_2', 'cast_3', \n",
    "                         'cast_4', 'cast_5', 'cast_6', 'cast_7']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d9a660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = cluster_df.set_index('album_id').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4273131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 특징 정보의 속성을 저장 \n",
    "cfg.n_genre_mid = meta_df['genre_mid'].nunique()\n",
    "cfg.cluster5 = cluster_df['clus5'].nunique()\n",
    "cfg.cluster8 = cluster_df['clus8'].nunique()\n",
    "cfg.cluster12 = cluster_df['clus12'].nunique()\n",
    "\n",
    "cfg.n_continuous_feats = 1 # 연속형 feature는 나이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4abb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    \"\"\"Neural Matrix Factorization Model\n",
    "        참고 문헌 : https://arxiv.org/abs/1708.05031\n",
    "\n",
    "    예시 :\n",
    "        model = NeuMF(cfg) \n",
    "        output = model.forward(user_ids, item_ids, [feat0, feat1]) \n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            cfg : config 파일로 네트워크 생성에 필요한 정보들을 담고 있음 \n",
    "        \"\"\"\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.n_users = cfg.n_users\n",
    "        self.n_items = cfg.n_items\n",
    "        self.emb_dim = cfg.emb_dim\n",
    "        self.layer_dim = cfg.layer_dim\n",
    "#         self.layer_dim2 = cfg.layer_dim2\n",
    "        self.n_continuous_feats = cfg.n_continuous_feats\n",
    "        self.n_genre_mid = cfg.n_genre_mid\n",
    "#         self.n_genre_large = cfg.n_genre_large\n",
    "        self.n_pr_interest_1 = cfg.n_pr_interest_keyword_1    \n",
    "        self.n_ch_interest_1 = cfg.n_ch_interest_keyword_1 \n",
    "#         self.n_pr_interest_2 = cfg.n_pr_interest_keyword_2    \n",
    "#         self.n_ch_interest_2 = cfg.n_ch_interest_keyword_2 \n",
    "#         self.n_pr_interest_3 = cfg.n_pr_interest_keyword_3    \n",
    "#         self.n_ch_interest_3 = cfg.n_ch_interest_keyword_3 \n",
    "        self.dropout = cfg.dropout\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Neural Matrix Factorization Model 생성\n",
    "            구현된 모습은 위의 그림을 참고 \n",
    "        \"\"\"\n",
    "        self.user_embedding_mf = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)  #256\n",
    "        self.item_embedding_mf = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "        \n",
    "        \n",
    "        self.sex_embedding = nn.Embedding(num_embeddings=2, embedding_dim=1)\n",
    "        self.genre_mid_embeddig = nn.Embedding(num_embeddings=self.n_genre_mid, embedding_dim=self.n_genre_mid//2)\n",
    "#         self.genre_large_embeddig = nn.Embedding(num_embeddings=self.n_genre_large, embedding_dim=self.n_genre_large//2)\n",
    "        \n",
    "        \n",
    "        self.pr_interest_1_embedding = nn.Embedding(num_embeddings=self.n_pr_interest_1, embedding_dim=self.n_pr_interest_1//2)\n",
    "        self.ch_interest_1_embedding = nn.Embedding(num_embeddings=self.n_ch_interest_1, embedding_dim=self.n_ch_interest_1//2)\n",
    "#         self.pr_interest_2_embedding = nn.Embedding(num_embeddings=self.n_pr_interest_2, embedding_dim=self.n_pr_interest_2//2)\n",
    "#         self.ch_interest_2_embedding = nn.Embedding(num_embeddings=self.n_ch_interest_2, embedding_dim=self.n_ch_interest_2//2)\n",
    "#         self.pr_interest_3_embedding = nn.Embedding(num_embeddings=self.n_pr_interest_3, embedding_dim=self.n_pr_interest_3//2)\n",
    "#         self.ch_interest_3_embedding = nn.Embedding(num_embeddings=self.n_ch_interest_3, embedding_dim=self.n_ch_interest_3//2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Linear(2*self.emb_dim +self.n_genre_mid//2 + self.n_pr_interest_1//2 + self.n_ch_interest_1//2+\n",
    "#                       self.n_pr_interest_2//2 + self.n_ch_interest_2//2+self.n_pr_interest_3//2 + self.n_ch_interest_3//2+\n",
    "                      self.n_continuous_feats +1, self.layer_dim),\n",
    "            nn.BatchNorm1d(self.layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout), \n",
    "            nn.Linear(self.layer_dim, self.layer_dim//2),\n",
    "            nn.BatchNorm1d(self.layer_dim//2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=self.dropout),\n",
    "#             nn.Linear(self.layer_dim2, self.layer_dim2//2), \n",
    "#             nn.ReLU(), \n",
    "#             nn.Dropout(p=self.dropout),\n",
    "            \n",
    "        )\n",
    "        self.affine_output = nn.Linear(self.layer_dim//2 + self.emb_dim, 1)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            normal_(module.weight.data, mean=0.0, std=0.01)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            normal_(module.weight.data, 0, 0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices, feats):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            user_indices : 유저의 인덱스 정보 \n",
    "                ex) tensor([ 3100,  3100,  ..., 14195, 14195])\n",
    "            item_indices : 아이템의 인덱스 정보\n",
    "                ex) tensor([   50,    65,   ..., 14960, 11527])\n",
    "            feats : 특징 정보 \n",
    "        Returns: \n",
    "            output : 유저-아이템 쌍에 대한 추천 결과 \n",
    "                ex) tensor([  9.4966,  22.0261, ..., -19.3535, -23.0212])\n",
    "        \"\"\"\n",
    "        user_embedding_mf = self.user_embedding_mf(user_indices)\n",
    "#         print(user_embedding_mf.shape)\n",
    "        item_embedding_mf = self.item_embedding_mf(item_indices)\n",
    "#         print(item_embedding_mf.shape)\n",
    "        mf_output = torch.mul(user_embedding_mf, item_embedding_mf)  # element wise\n",
    "        \n",
    "        user_embedding_mlp = self.user_embedding_mlp(user_indices)\n",
    "        item_embedding_mlp = self.item_embedding_mlp(item_indices)\n",
    "        genre_mid_embedding_mlp = self.genre_mid_embeddig(feats[5])\n",
    "#         genre_large_embedding_mlp = self.genre_large_embeddig(feats[4])\n",
    "        pr_interest_1_embedding_mlp = self.pr_interest_1_embedding(feats[3])\n",
    "        ch_interest_1_embedding_mlp = self.ch_interest_1_embedding(feats[4])\n",
    "#         pr_interest_2_embedding_mlp = self.pr_interest_2_embedding(feats[2])\n",
    "#         ch_interest_2_embedding_mlp = self.ch_interest_2_embedding(feats[3])\n",
    "#         pr_interest_3_embedding_mlp = self.pr_interest_3_embedding(feats[2])\n",
    "#         ch_interest_3_embedding_mlp = self.ch_interest_3_embedding(feats[3])\n",
    "        \n",
    "        sex_embedding_mlp = self.sex_embedding(feats[2])\n",
    "        input_feature = torch.cat((user_embedding_mlp, item_embedding_mlp,genre_mid_embedding_mlp,\n",
    "                                   pr_interest_1_embedding_mlp,ch_interest_1_embedding_mlp,\n",
    "#                                    pr_interest_2_embedding_mlp,ch_interest_2_embedding_mlp,\n",
    "#                                    pr_interest_3_embedding_mlp,ch_interest_3_embedding_mlp,\n",
    "                                   sex_embedding_mlp,feats[0].unsqueeze(1),feats[1].unsqueeze(1)), -1)\n",
    "        mlp_output = self.mlp_layers(input_feature)\n",
    "        \n",
    "        output = torch.cat([mlp_output, mf_output], dim=-1)\n",
    "        output = self.affine_output(output).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e577a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_UIdataset(train, neg_ratio):\n",
    "    \n",
    "    UIdataset = {}\n",
    "    for user_id, items_by_user in enumerate(train):\n",
    "        UIdataset[user_id] = []\n",
    "        # positive 샘플 계산 \n",
    "        pos_item_ids = np.where(items_by_user > 0.5)[0]\n",
    "        num_pos_samples = len(pos_item_ids)\n",
    "\n",
    "        # negative 샘플 계산 (random negative sampling) \n",
    "        num_neg_samples = neg_ratio * num_pos_samples\n",
    "        neg_items = np.where(items_by_user < 0.5)[0]\n",
    "        neg_item_ids = np.random.choice(neg_items, min(num_neg_samples, len(neg_items)), replace=False)\n",
    "        UIdataset[user_id].append(np.concatenate([pos_item_ids, neg_item_ids]))\n",
    "        \n",
    "        # feature 'age' \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(user_features['age'][user_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # feature 'sex' \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(user_features['sex'][user_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        \n",
    "        # feature 'genre_mid'\n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(item_features['genre_mid'][item_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # feature 'cluster8'\n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(cluster_dict['clus8'][item_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        \n",
    "        # label 저장  \n",
    "        pos_labels = np.ones(len(pos_item_ids))\n",
    "        neg_labels = np.zeros(len(neg_item_ids))\n",
    "        UIdataset[user_id].append(np.concatenate([pos_labels, neg_labels]))\n",
    "\n",
    "    return UIdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4812cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UIdataset = make_UIdataset(train, neg_ratio=cfg.neg_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e41cc702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   16,    17,    18, ...,  9586, 18991,  9442]),\n",
       " array([5, 5, 5, ..., 5, 5, 5]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " array([4, 4, 4, ..., 5, 1, 1]),\n",
       " array([6, 6, 6, ..., 1, 0, 0]),\n",
       " array([1., 1., 1., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UIdataset[3]\n",
    "# 1. 나이\n",
    "# 2. 성별\n",
    "# 3. genre\n",
    "# 4. cluster8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62798928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batchdata(user_indices, batch_idx, batch_size):\n",
    "    \n",
    "    batch_user_indices = user_indices[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "    batch_user_ids = []\n",
    "    batch_item_ids = []\n",
    "    batch_feat0 = []\n",
    "    batch_feat1 = []\n",
    "    batch_feat2 = []\n",
    "    batch_feat3 = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for user_id in batch_user_indices:\n",
    "        \n",
    "        item_ids = UIdataset[user_id][0] # 시청 아이템 index\n",
    "        \n",
    "        feat0 = UIdataset[user_id][1] # 나이\n",
    "        feat1 = UIdataset[user_id][2] # 성별\n",
    "        \n",
    "        feat2 = UIdataset[user_id][3] # 장르\n",
    "        feat3 = UIdataset[user_id][4] # cluster8\n",
    "        \n",
    "        labels = UIdataset[user_id][5] # 평점\n",
    "        \n",
    "        user_ids = np.full(len(item_ids), user_id)\n",
    "        batch_user_ids.extend(user_ids.tolist())\n",
    "        batch_item_ids.extend(item_ids.tolist())\n",
    "        \n",
    "        batch_feat0.extend(feat0.tolist())\n",
    "        batch_feat1.extend(feat1.tolist())\n",
    "        batch_feat2.extend(feat2.tolist())\n",
    "        batch_feat3.extend(feat3.tolist())\n",
    "        \n",
    "        batch_labels.extend(labels.tolist())\n",
    "        \n",
    "    return batch_user_ids, batch_item_ids, batch_feat0, batch_feat1, batch_feat2, batch_feat3, batch_labels\n",
    "\n",
    "def update_avg(curr_avg, val, idx):\n",
    "    \"\"\" 현재 epoch 까지의 평균 값을 계산 \n",
    "    \"\"\"\n",
    "    return (curr_avg * idx + val) / (idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7297a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(cfg, model, optimizer, criterion): \n",
    "    model.train()\n",
    "    curr_loss_avg = 0.0\n",
    "\n",
    "    user_indices = np.arange(cfg.n_users)\n",
    "    np.random.RandomState(cfg.epoch).shuffle(user_indices)\n",
    "    batch_num = int(len(user_indices) / cfg.batch_size) + 1\n",
    "    bar = tqdm(range(batch_num), leave=False)\n",
    "    \n",
    "    for step, batch_idx in enumerate(bar):\n",
    "        user_ids, item_ids, feat0, feat1, feat2, feat3, labels = make_batchdata(user_indices, batch_idx, cfg.batch_size)\n",
    "        \n",
    "        # 배치 사용자 단위로 학습\n",
    "        user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "        item_ids = torch.LongTensor(item_ids).to(cfg.device)\n",
    "        \n",
    "        feat0 = torch.FloatTensor(feat0).to(cfg.device) # 나이: 연속형 -> FloatTensor\n",
    "        \n",
    "        # Long Tensor\n",
    "        feat1 = torch.LongTensor(feat1).to(cfg.device) # 성별\n",
    "        \n",
    "        feat2 = torch.LongTensor(feat2).to(cfg.device) # genre\n",
    "        feat3= torch.LongTensor(feat3).to(cfg.device) # cluster8\n",
    "        \n",
    "        labels = torch.FloatTensor(labels).to(cfg.device)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # grad 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 forward\n",
    "        output = model.forward(user_ids, item_ids, [feat0, feat1, feat2, feat3])\n",
    "        output = output.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 최적화\n",
    "        optimizer.step()    \n",
    "        if torch.isnan(loss):\n",
    "            print('Loss NAN. Train finish.')\n",
    "            break\n",
    "        curr_loss_avg = update_avg(curr_loss_avg, loss, step)\n",
    "        \n",
    "        msg = f\"epoch: {cfg.epoch}, \"\n",
    "        msg += f\"loss: {curr_loss_avg.item():.5f}, \"\n",
    "        msg += f\"lr: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        bar.set_description(msg)\n",
    "    rets = {'losses': np.around(curr_loss_avg.item(), 5)}\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c03f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(cfg, model, data, mode='valid'):\n",
    "    pred_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    query_user_ids = data['profile_id'].unique() # 추론할 모든 user array 집합\n",
    "    \n",
    "    full_item_ids = np.array([c for c in range(cfg.n_items)]) # 추론할 모든 item array 집합\n",
    "    full_item_ids_feat2 = [item_features['genre_mid'][c] for c in full_item_ids]\n",
    "    full_item_ids_feat3 = [cluster_dict['clus8'][c] for c in full_item_ids] # cluster8\n",
    "    \n",
    "    for user_id in tqdm(query_user_ids):\n",
    "        with torch.no_grad():\n",
    "            user_ids = np.full(cfg.n_items, user_id)\n",
    "            \n",
    "            user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "            item_ids = torch.LongTensor(full_item_ids).to(cfg.device)\n",
    "            \n",
    "            # 사용자 feature\n",
    "            feat0 = np.full(cfg.n_items, user_features['age'][user_id]) # age\n",
    "            feat0 = torch.FloatTensor(feat0).to(cfg.device)\n",
    "            \n",
    "            feat1 = np.full(cfg.n_items, user_features['sex'][user_id]) # sex\n",
    "            feat1 = torch.LongTensor(feat1).to(cfg.device)\n",
    "            \n",
    "            # 아이템 feature\n",
    "            feat2 = torch.LongTensor(full_item_ids_feat2).to(cfg.device)\n",
    "            feat3 = torch.LongTensor(full_item_ids_feat3).to(cfg.device)\n",
    "            \n",
    "            eval_output = model.forward(user_ids, item_ids, [feat0, feat1, feat2, feat3]).detach().cpu().numpy()\n",
    "            pred_u_score = eval_output.reshape(-1)   \n",
    "        \n",
    "        pred_u_idx = np.argsort(pred_u_score)[::-1]\n",
    "        pred_u = full_item_ids[pred_u_idx]\n",
    "        pred_list.append(list(pred_u[:cfg.top_k]))\n",
    "        \n",
    "    pred = pd.DataFrame()\n",
    "    pred['profile_id'] = query_user_ids\n",
    "    pred['predicted_list'] = pred_list\n",
    "    \n",
    "    # 모델 성능 확인 \n",
    "    if mode == 'valid':\n",
    "        rets = evaluation(data, pred)\n",
    "        return rets, pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0c9913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallk(actual, predicted, k = 25):\n",
    "    set_actual = set(actual)\n",
    "    recall_k = len(set_actual & set(predicted[:k])) / min(k, len(set_actual))\n",
    "    return recall_k\n",
    "\n",
    "def unique(sequence):\n",
    "    # preserves order\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "def ndcgk(actual, predicted, k = 25):\n",
    "    set_actual = set(actual)\n",
    "    idcg = sum([1.0 / np.log(i + 2) for i in range(min(k, len(set_actual)))]) \n",
    "    dcg = 0.0\n",
    "    unique_predicted = unique(predicted[:k])\n",
    "    for i, r in enumerate(unique_predicted):\n",
    "        if r in set_actual:\n",
    "            dcg += 1.0 / np.log(i + 2)\n",
    "    ndcg_k = dcg / idcg\n",
    "    return ndcg_k\n",
    "\n",
    "def evaluation(gt, pred):\n",
    "    \n",
    "    gt = gt.groupby('profile_id')['album_id'].unique().to_frame().reset_index()\n",
    "    gt.columns = ['profile_id', 'actual_list']\n",
    "\n",
    "    evaluated_data = pd.merge(pred, gt, how = 'left', on = 'profile_id')\n",
    "\n",
    "    evaluated_data['Recall@25'] = evaluated_data.apply(lambda x: recallk(x.actual_list, x.predicted_list), axis=1)\n",
    "    evaluated_data['NDCG@25'] = evaluated_data.apply(lambda x: ndcgk(x.actual_list, x.predicted_list), axis=1)\n",
    "\n",
    "    recall = evaluated_data['Recall@25'].mean()\n",
    "    ndcg = evaluated_data['NDCG@25'] .mean()\n",
    "    coverage = (evaluated_data['predicted_list'].apply(lambda x: x[:cfg.top_k]).explode().nunique())/meta_df.index.nunique()\n",
    "\n",
    "    score = 0.75*recall + 0.25*ndcg\n",
    "    rets = {\"recall\" :recall, \n",
    "            \"ndcg\" :ndcg, \n",
    "            \"coverage\" :coverage, \n",
    "            \"score\" :score}\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddf2a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 생성 및 optimizer, loss 함수 설정 \n",
    "model = NeuMF(cfg).to(cfg.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.reg_lambda)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.91)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "716c5f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b67240be3b64d9dbaee7183dc0e4d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch,Train Loss,Valid Recall@25,Valid NDCG@25,Valid Coverage,Valid Score\n",
      "00  13258.392580  0.591660  0.499085  0.248627  0.568516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7d7532507743429b17a716401cc6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01  4079.033690  0.615045  0.509248  0.262671  0.588596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c654ae1b3cf4437959e6535de510e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02  3276.695560  0.631408  0.507447  0.258658  0.600418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec3a4f915064a949da42ec6dfc26644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03  2464.078120  0.649035  0.508765  0.261417  0.613967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291b560f0a85408882fbd41b53bff68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04  1714.737430  0.645896  0.495131  0.273254  0.608205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1343e0df6f444c42b76b3d2c4dc3a1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05  1080.913090  0.649040  0.496890  0.294871  0.611003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f645df7bf848eb989ce3b3e90449b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06  675.606690  0.639794  0.482320  0.302545  0.600425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9aac05a8b642bb8923964d1ea58b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07  444.111420  0.643601  0.485914  0.310771  0.604179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b75aba41de41eba990779bf4418b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08  304.613650  0.637845  0.480143  0.307812  0.598420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56d213130ab434283406f5505448126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# cfg.check_epoch 번의 epoch 마다 성능 확인 \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m cfg\u001b[38;5;241m.\u001b[39mcheck_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[0;32m---> 10\u001b[0m     valid_results, _ \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid Recall@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mtop_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: valid_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid Score\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m         }\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 검증 성능 확인 \u001b[39;00m\n",
      "Cell \u001b[0;32mIn [28], line 35\u001b[0m, in \u001b[0;36mvalid_epoch\u001b[0;34m(cfg, model, data, mode)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(user_item_watch) \u001b[38;5;241m==\u001b[39m cfg\u001b[38;5;241m.\u001b[39mn_items, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLENGTH ERROR!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m feat1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(user_item_watch)\n\u001b[0;32m---> 35\u001b[0m feat1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m feat2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(cfg\u001b[38;5;241m.\u001b[39mn_items, user_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m][user_id]) \u001b[38;5;66;03m# sex\u001b[39;00m\n\u001b[1;32m     38\u001b[0m feat2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(feat2)\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_logs = defaultdict(list)\n",
    "best_scores  = 0\n",
    "for epoch in range(cfg.epochs+1):\n",
    "    cfg.epoch = epoch\n",
    "    train_results = train_epoch(cfg, model, optimizer, criterion)\n",
    "    \n",
    "    scheduler.step()\n",
    "    # cfg.check_epoch 번의 epoch 마다 성능 확인 \n",
    "    if epoch % cfg.check_epoch == 0: \n",
    "        valid_results, _ = valid_epoch(cfg, model, valid)\n",
    "\n",
    "        logs = {\n",
    "            'Train Loss': train_results['losses'],\n",
    "            f'Valid Recall@{cfg.top_k}': valid_results['recall'],\n",
    "            f'Valid NDCG@{cfg.top_k}': valid_results['ndcg'],\n",
    "            'Valid Coverage': valid_results['coverage'],\n",
    "            'Valid Score': valid_results['score'],\n",
    "            }\n",
    "\n",
    "        # 검증 성능 확인 \n",
    "        for key, value in logs.items():\n",
    "            total_logs[key].append(value)\n",
    "\n",
    "        if epoch == 0:\n",
    "            print(\"Epoch\", end=\",\")\n",
    "            print(\",\".join(logs.keys()))\n",
    "\n",
    "        print(f\"{epoch:02d}  \", end=\"\")\n",
    "        print(\"  \".join([f\"{v:0.6f}\" for v in logs.values()]))\n",
    "        \n",
    "        # 가장 성능이 좋은 가중치 파일을 저장 \n",
    "        if best_scores <= valid_results['score']: \n",
    "            best_scores = valid_results['score']\n",
    "            torch.save(model.state_dict(), os.path.join(saved_path, 'model(best_scores)_newexp15.pth'))  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d99f5db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(saved_path, 'model(best_scores)_newexp15.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e7a91fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82195a3068bd4e39b61a5e4405ae8134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission_path = os.path.join(data_path, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission = valid_epoch(cfg, model, submission, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "818ce8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(output_path, 'submission_15.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec98342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
