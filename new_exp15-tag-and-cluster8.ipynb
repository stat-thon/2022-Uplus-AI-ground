{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367adec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotnine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset, DataLoader\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotnine\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotnine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotnine'"
     ]
    }
   ],
   "source": [
    "# 패키지 로드\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import os, random\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9478ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 28 12:14:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:1A:00.0 Off |                  Off |\n",
      "| 33%   37C    P2    60W / 260W |   1130MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     On   | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   46C    P2   105W / 260W |  21134MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:3E:00.0 Off |                  Off |\n",
      "| 33%   34C    P8    15W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:40:00.0 Off |                  Off |\n",
      "| 33%   54C    P2   205W / 260W |  48121MiB / 48601MiB |     77%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 33%   55C    P2   243W / 260W |  48122MiB / 48601MiB |     89%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 \n",
    "class cfg: \n",
    "    gpu_idx = 2\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "    top_k = 25 #############\n",
    "    seed = 42\n",
    "    neg_ratio = 100 #######\n",
    "    test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "118803c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정 \n",
    "cfg.batch_size = 256\n",
    "cfg.emb_dim = 256\n",
    "cfg.layer_dim = 512\n",
    "cfg.dropout = 0.5\n",
    "cfg.epochs = 10\n",
    "cfg.learning_rate = 0.0025\n",
    "cfg.reg_lambda = 0\n",
    "cfg.check_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2491a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정 \n",
    "def seed_everything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "seed_everything(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15057cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "data_path = './data'\n",
    "saved_path = './code/saved'\n",
    "output_path = './code/submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6111bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.read_csv(os.path.join(data_path, 'history_data.csv'), encoding='utf-8')\n",
    "profile_df = pd.read_csv(os.path.join(data_path, 'profile_data.csv'), encoding='utf-8')\n",
    "meta_df = pd.read_csv(os.path.join(data_path, 'meta_data.csv'), encoding='utf-8')\n",
    "watch_e_df = pd.read_csv(os.path.join(data_path, 'watch_e_data.csv'), encoding='utf-8')\n",
    "search_df =  pd.read_csv(os.path.join(data_path, 'search_data.csv'), encoding='utf-8')\n",
    "buy_df = pd.read_csv(os.path.join(data_path, 'buy_data.csv'), encoding='utf-8')\n",
    "meta_plus_df = pd.read_csv(os.path.join(data_path, 'meta_data_plus.csv'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee019f53",
   "metadata": {},
   "source": [
    "## make 'watch' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e95c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('watching2.pickle', 'rb') as f:\n",
    "    watching2 = pickle.load(f)\n",
    "\n",
    "with open('tag_for_all_id.pickle', 'rb') as f:\n",
    "    tag = pickle.load(f)\n",
    "    \n",
    "with open('clusterset.pickle', 'rb') as f:\n",
    "    cluster_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1918491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_dict = dict()\n",
    "for index, profile, album, watch in watching2.itertuples():\n",
    "    watch_dict[(profile, album)] = watch\n",
    "    \n",
    "# print(watch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf763e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 (중복제거) \n",
    "# 참고 : drop_duplicates의 subset을 무엇으로 구성하냐에 따라서 제거되는 항목들이 다름 \n",
    "# ex) 'profile_id', 'album_id' : 중복된 시청이력 모두 제거 / 'profile_id', 'album_id', 'log_time' : 같은 시간에 시청한 이력만 제거 \n",
    "data = history_df[['profile_id', 'log_time', 'album_id']].drop_duplicates(subset=['profile_id', 'album_id', 'log_time']).sort_values(by = ['profile_id', 'log_time']).reset_index(drop = True)\n",
    "data['rating'] = 1\n",
    "\n",
    "cfg.n_users = data.profile_id.max()+1\n",
    "cfg.n_items = data.album_id.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462adf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25917"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a559d77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기: (719401, 4)\n",
      "검증 데이터 크기: (179851, 4)\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증 데이터 분리\n",
    "train, valid = train_test_split(\n",
    "    data, test_size=cfg.test_size, random_state=cfg.seed,\n",
    ")\n",
    "print('학습 데이터 크기:', train.shape)\n",
    "print('검증 데이터 크기:', valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11173f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af3c0e38a9d414d9eb17b5ac4e8e2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 형태: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix 형태로 변환 \n",
    "train = train.to_numpy()\n",
    "matrix = sparse.lil_matrix((cfg.n_users, cfg.n_items))  \n",
    "for (p, _, i, r) in tqdm(train):\n",
    "    matrix[p, i] = r\n",
    "    \n",
    "train = sparse.csr_matrix(matrix)\n",
    "train = train.toarray()\n",
    "print(\"train 형태: \\n\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3bc1ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33033, 25917)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e165057",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = profile_df.set_index('profile_id')\n",
    "\n",
    "le = LabelEncoder()\n",
    "profile_df['sex'] = le.fit_transform(profile_df['sex'])\n",
    "profile_df['pr_interest_keyword_cd_1'] = le.fit_transform(profile_df['pr_interest_keyword_cd_1'])\n",
    "profile_df['pr_interest_keyword_cd_2'] = le.fit_transform(profile_df['pr_interest_keyword_cd_2'])\n",
    "profile_df['pr_interest_keyword_cd_3'] = le.fit_transform(profile_df['pr_interest_keyword_cd_3'])\n",
    "profile_df['ch_interest_keyword_cd_1'] = le.fit_transform(profile_df['ch_interest_keyword_cd_1'])\n",
    "profile_df['ch_interest_keyword_cd_2'] = le.fit_transform(profile_df['ch_interest_keyword_cd_2'])\n",
    "profile_df['ch_interest_keyword_cd_3'] = le.fit_transform(profile_df['ch_interest_keyword_cd_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "020d3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 특징 정보 추출 \n",
    "user_features = profile_df[['age', 'sex',\n",
    "                            'pr_interest_keyword_cd_1',\n",
    "                            'pr_interest_keyword_cd_2',\n",
    "                            'pr_interest_keyword_cd_3',\n",
    "                            'ch_interest_keyword_cd_1',\n",
    "                            'ch_interest_keyword_cd_2',\n",
    "                            'ch_interest_keyword_cd_3']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "162c05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.n_pr_interest_keyword_1 = profile_df['pr_interest_keyword_cd_1'].nunique()\n",
    "cfg.n_ch_interest_keyword_1 = profile_df['ch_interest_keyword_cd_1'].nunique()\n",
    "cfg.n_pr_interest_keyword_2 = profile_df['pr_interest_keyword_cd_2'].nunique()\n",
    "cfg.n_ch_interest_keyword_2 = profile_df['ch_interest_keyword_cd_2'].nunique()\n",
    "cfg.n_pr_interest_keyword_3 = profile_df['pr_interest_keyword_cd_3'].nunique()\n",
    "cfg.n_ch_interest_keyword_3 = profile_df['ch_interest_keyword_cd_3'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b70d0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = meta_df.set_index('album_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9257e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['genre_large'] = le.fit_transform(meta_df['genre_large'])\n",
    "meta_df['genre_mid'] = le.fit_transform(meta_df['genre_mid'])\n",
    "meta_df['genre_small'] = le.fit_transform(meta_df['genre_small'])\n",
    "meta_df['cast_1'] = le.fit_transform(meta_df['cast_1'])\n",
    "meta_df['cast_2'] = le.fit_transform(meta_df['cast_2'])\n",
    "meta_df['cast_3'] = le.fit_transform(meta_df['cast_3'])\n",
    "meta_df['cast_4'] = le.fit_transform(meta_df['cast_4'])\n",
    "meta_df['cast_5'] = le.fit_transform(meta_df['cast_5'])\n",
    "meta_df['cast_6'] = le.fit_transform(meta_df['cast_6'])\n",
    "meta_df['cast_7'] = le.fit_transform(meta_df['cast_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b507e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = meta_df[['genre_large', 'genre_mid', 'genre_small',\n",
    "                         'cast_1', 'cast_2', 'cast_3', \n",
    "                         'cast_4', 'cast_5', 'cast_6', 'cast_7']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699c6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "tag['tag'] = le.fit_transform(tag['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46635d73",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': {749: 27,\n",
       "  750: 27,\n",
       "  2131: 27,\n",
       "  2625: 27,\n",
       "  2594: 27,\n",
       "  2637: 27,\n",
       "  2636: 27,\n",
       "  748: 27,\n",
       "  1381: 27,\n",
       "  1380: 27,\n",
       "  746: 27,\n",
       "  745: 27,\n",
       "  744: 27,\n",
       "  628: 27,\n",
       "  627: 27,\n",
       "  626: 27,\n",
       "  631: 27,\n",
       "  630: 27,\n",
       "  629: 27,\n",
       "  6744: 27,\n",
       "  7037: 27,\n",
       "  668: 27,\n",
       "  632: 27,\n",
       "  817: 27,\n",
       "  816: 27,\n",
       "  815: 27,\n",
       "  26077: 14,\n",
       "  26078: 14,\n",
       "  26079: 14,\n",
       "  21481: 14,\n",
       "  26080: 14,\n",
       "  13771: 14,\n",
       "  26081: 14,\n",
       "  19720: 14,\n",
       "  26082: 14,\n",
       "  20690: 14,\n",
       "  26083: 14,\n",
       "  20703: 14,\n",
       "  26084: 14,\n",
       "  26068: 14,\n",
       "  9826: 14,\n",
       "  25095: 14,\n",
       "  3881: 4,\n",
       "  10487: 21,\n",
       "  9460: 19,\n",
       "  9459: 21,\n",
       "  9458: 21,\n",
       "  10513: 21,\n",
       "  6733: 21,\n",
       "  6732: 3,\n",
       "  6731: 21,\n",
       "  10512: 21,\n",
       "  9808: 19,\n",
       "  10515: 21,\n",
       "  10514: 19,\n",
       "  25328: 14,\n",
       "  26085: 14,\n",
       "  7856: 3,\n",
       "  4503: 3,\n",
       "  9814: 19,\n",
       "  9809: 4,\n",
       "  26086: 14,\n",
       "  25322: 14,\n",
       "  25311: 14,\n",
       "  25317: 14,\n",
       "  25318: 14,\n",
       "  25319: 14,\n",
       "  26087: 14,\n",
       "  25312: 14,\n",
       "  26088: 14,\n",
       "  25326: 14,\n",
       "  10605: 3,\n",
       "  7884: 3,\n",
       "  10325: 3,\n",
       "  2088: 14,\n",
       "  2087: 14,\n",
       "  2086: 14,\n",
       "  1981: 14,\n",
       "  1455: 14,\n",
       "  3886: 3,\n",
       "  4506: 0,\n",
       "  4505: 3,\n",
       "  4504: 28,\n",
       "  25321: 14,\n",
       "  25314: 14,\n",
       "  25315: 14,\n",
       "  26089: 14,\n",
       "  26090: 14,\n",
       "  10613: 3,\n",
       "  10606: 3,\n",
       "  10607: 3,\n",
       "  10608: 3,\n",
       "  10610: 3,\n",
       "  7857: 15,\n",
       "  10612: 3,\n",
       "  10611: 15,\n",
       "  10609: 3,\n",
       "  1462: 14,\n",
       "  1461: 14,\n",
       "  1460: 14,\n",
       "  1459: 14,\n",
       "  1458: 14,\n",
       "  26091: 14,\n",
       "  26092: 14,\n",
       "  26093: 14,\n",
       "  25325: 14,\n",
       "  25324: 14,\n",
       "  9457: 21,\n",
       "  19404: 0,\n",
       "  19405: 3,\n",
       "  19406: 20,\n",
       "  19907: 3,\n",
       "  21022: 19,\n",
       "  2109: 14,\n",
       "  1464: 14,\n",
       "  1463: 14,\n",
       "  1457: 14,\n",
       "  1456: 14,\n",
       "  26094: 14,\n",
       "  26095: 14,\n",
       "  26096: 14,\n",
       "  26097: 14,\n",
       "  26098: 14,\n",
       "  4884: 14,\n",
       "  4883: 14,\n",
       "  2552: 14,\n",
       "  2551: 14,\n",
       "  2110: 14,\n",
       "  25327: 14,\n",
       "  25323: 14,\n",
       "  26099: 14,\n",
       "  25320: 14,\n",
       "  26100: 14,\n",
       "  25316: 14,\n",
       "  25313: 14,\n",
       "  1769: 14,\n",
       "  1768: 14,\n",
       "  1767: 14,\n",
       "  4886: 14,\n",
       "  4885: 14,\n",
       "  1774: 14,\n",
       "  1773: 14,\n",
       "  1772: 14,\n",
       "  1771: 14,\n",
       "  1770: 14,\n",
       "  1779: 14,\n",
       "  1778: 14,\n",
       "  1777: 14,\n",
       "  1776: 14,\n",
       "  1775: 14,\n",
       "  1784: 14,\n",
       "  1783: 14,\n",
       "  1782: 14,\n",
       "  1781: 14,\n",
       "  1780: 14,\n",
       "  1786: 14,\n",
       "  1785: 14,\n",
       "  6536: 27,\n",
       "  15642: 27,\n",
       "  1789: 14,\n",
       "  1788: 14,\n",
       "  1787: 14,\n",
       "  1454: 14,\n",
       "  1453: 14,\n",
       "  1451: 14,\n",
       "  1450: 14,\n",
       "  1449: 14,\n",
       "  1452: 14,\n",
       "  1790: 14,\n",
       "  17221: 18,\n",
       "  26101: 18,\n",
       "  26102: 18,\n",
       "  25058: 18,\n",
       "  10008: 18,\n",
       "  26103: 6,\n",
       "  26104: 6,\n",
       "  25833: 6,\n",
       "  26105: 6,\n",
       "  14930: 6,\n",
       "  14938: 6,\n",
       "  14929: 6,\n",
       "  14928: 6,\n",
       "  26106: 2,\n",
       "  26107: 2,\n",
       "  26108: 2,\n",
       "  26109: 2,\n",
       "  26110: 2,\n",
       "  26111: 2,\n",
       "  26112: 2,\n",
       "  26113: 2,\n",
       "  26114: 18,\n",
       "  26115: 18,\n",
       "  26116: 18,\n",
       "  17599: 18,\n",
       "  26117: 18,\n",
       "  26118: 2,\n",
       "  26119: 2,\n",
       "  26120: 2,\n",
       "  26121: 2,\n",
       "  26122: 2,\n",
       "  26123: 2,\n",
       "  26124: 2,\n",
       "  26125: 2,\n",
       "  26126: 2,\n",
       "  26127: 18,\n",
       "  26128: 2,\n",
       "  6131: 1,\n",
       "  6449: 1,\n",
       "  26129: 18,\n",
       "  26130: 2,\n",
       "  26131: 2,\n",
       "  26132: 2,\n",
       "  25267: 6,\n",
       "  26133: 18,\n",
       "  26134: 2,\n",
       "  26135: 2,\n",
       "  26136: 6,\n",
       "  26137: 18,\n",
       "  3397: 2,\n",
       "  3396: 2,\n",
       "  3338: 2,\n",
       "  3340: 2,\n",
       "  3342: 2,\n",
       "  3343: 2,\n",
       "  3339: 2,\n",
       "  438: 2,\n",
       "  436: 2,\n",
       "  437: 2,\n",
       "  14942: 1,\n",
       "  26138: 18,\n",
       "  26139: 18,\n",
       "  26140: 2,\n",
       "  26141: 2,\n",
       "  26142: 2,\n",
       "  26143: 18,\n",
       "  26144: 2,\n",
       "  26145: 2,\n",
       "  3405: 2,\n",
       "  3406: 2,\n",
       "  3398: 2,\n",
       "  3400: 2,\n",
       "  3401: 2,\n",
       "  3402: 2,\n",
       "  485: 2,\n",
       "  3403: 2,\n",
       "  484: 2,\n",
       "  3404: 2,\n",
       "  26146: 2,\n",
       "  26147: 6,\n",
       "  26148: 18,\n",
       "  26149: 2,\n",
       "  26150: 2,\n",
       "  26151: 6,\n",
       "  26152: 18,\n",
       "  26153: 2,\n",
       "  26154: 18,\n",
       "  462: 2,\n",
       "  3417: 2,\n",
       "  3418: 2,\n",
       "  461: 2,\n",
       "  3419: 2,\n",
       "  460: 2,\n",
       "  26155: 18,\n",
       "  26156: 2,\n",
       "  26157: 2,\n",
       "  26158: 18,\n",
       "  26159: 2,\n",
       "  26160: 2,\n",
       "  26161: 18,\n",
       "  26162: 2,\n",
       "  26163: 6,\n",
       "  26164: 18,\n",
       "  26165: 2,\n",
       "  26166: 2,\n",
       "  26167: 6,\n",
       "  26168: 2,\n",
       "  26169: 2,\n",
       "  26170: 2,\n",
       "  26171: 18,\n",
       "  17740: 1,\n",
       "  26172: 2,\n",
       "  17741: 1,\n",
       "  26173: 18,\n",
       "  26174: 2,\n",
       "  26175: 2,\n",
       "  26176: 18,\n",
       "  26177: 2,\n",
       "  26178: 2,\n",
       "  26179: 18,\n",
       "  26180: 2,\n",
       "  26181: 6,\n",
       "  26182: 18,\n",
       "  26183: 2,\n",
       "  26184: 2,\n",
       "  26185: 6,\n",
       "  26186: 2,\n",
       "  26187: 18,\n",
       "  26188: 2,\n",
       "  26189: 18,\n",
       "  17742: 1,\n",
       "  26190: 2,\n",
       "  26191: 2,\n",
       "  26192: 18,\n",
       "  26193: 2,\n",
       "  26194: 2,\n",
       "  26195: 18,\n",
       "  26196: 2,\n",
       "  24386: 6,\n",
       "  26197: 18,\n",
       "  26198: 2,\n",
       "  26199: 2,\n",
       "  26200: 6,\n",
       "  26201: 2,\n",
       "  26202: 18,\n",
       "  26203: 2,\n",
       "  17743: 1,\n",
       "  26204: 18,\n",
       "  26205: 2,\n",
       "  26206: 2,\n",
       "  26207: 18,\n",
       "  26208: 2,\n",
       "  26209: 2,\n",
       "  26210: 2,\n",
       "  26211: 6,\n",
       "  26212: 18,\n",
       "  26213: 18,\n",
       "  26214: 2,\n",
       "  26215: 2,\n",
       "  26216: 6,\n",
       "  26217: 2,\n",
       "  26218: 18,\n",
       "  26219: 2,\n",
       "  26220: 18,\n",
       "  17744: 1,\n",
       "  26221: 2,\n",
       "  26222: 2,\n",
       "  26223: 18,\n",
       "  26224: 2,\n",
       "  26225: 2,\n",
       "  26226: 6,\n",
       "  26227: 18,\n",
       "  26228: 2,\n",
       "  26229: 18,\n",
       "  26230: 2,\n",
       "  26231: 2,\n",
       "  26232: 6,\n",
       "  26233: 6,\n",
       "  26234: 6,\n",
       "  26235: 6,\n",
       "  26236: 6,\n",
       "  26237: 6,\n",
       "  26238: 6,\n",
       "  26239: 6,\n",
       "  26240: 6,\n",
       "  26241: 6,\n",
       "  26242: 6,\n",
       "  26243: 6,\n",
       "  26244: 6,\n",
       "  26245: 6,\n",
       "  26246: 18,\n",
       "  26247: 2,\n",
       "  26248: 6,\n",
       "  26249: 6,\n",
       "  26250: 2,\n",
       "  26251: 2,\n",
       "  20735: 1,\n",
       "  26252: 18,\n",
       "  26253: 6,\n",
       "  26254: 6,\n",
       "  26255: 6,\n",
       "  26256: 2,\n",
       "  26257: 6,\n",
       "  26258: 6,\n",
       "  26259: 6,\n",
       "  26260: 18,\n",
       "  26261: 2,\n",
       "  26262: 2,\n",
       "  26263: 6,\n",
       "  26264: 6,\n",
       "  26265: 6,\n",
       "  26266: 6,\n",
       "  26267: 18,\n",
       "  26268: 2,\n",
       "  26269: 6,\n",
       "  26270: 6,\n",
       "  26271: 6,\n",
       "  26272: 6,\n",
       "  26273: 18,\n",
       "  26274: 2,\n",
       "  26275: 2,\n",
       "  26276: 6,\n",
       "  26277: 6,\n",
       "  26278: 6,\n",
       "  26279: 18,\n",
       "  26280: 2,\n",
       "  26281: 2,\n",
       "  26282: 6,\n",
       "  26283: 6,\n",
       "  26284: 6,\n",
       "  26285: 18,\n",
       "  25069: 1,\n",
       "  26286: 2,\n",
       "  26287: 2,\n",
       "  26288: 6,\n",
       "  26289: 6,\n",
       "  26290: 18,\n",
       "  26291: 2,\n",
       "  26292: 2,\n",
       "  26293: 2,\n",
       "  26294: 6,\n",
       "  26295: 6,\n",
       "  26296: 6,\n",
       "  26297: 18,\n",
       "  26298: 2,\n",
       "  26299: 6,\n",
       "  26300: 6,\n",
       "  26301: 6,\n",
       "  26302: 18,\n",
       "  26303: 2,\n",
       "  26304: 6,\n",
       "  26305: 6,\n",
       "  26306: 18,\n",
       "  26307: 2,\n",
       "  26308: 2,\n",
       "  26309: 6,\n",
       "  26310: 6,\n",
       "  26311: 18,\n",
       "  20736: 1,\n",
       "  26312: 2,\n",
       "  26313: 2,\n",
       "  26314: 6,\n",
       "  26315: 6,\n",
       "  26316: 18,\n",
       "  26317: 2,\n",
       "  26318: 2,\n",
       "  26319: 14,\n",
       "  26320: 14,\n",
       "  15251: 14,\n",
       "  26321: 14,\n",
       "  26322: 14,\n",
       "  26323: 14,\n",
       "  26324: 14,\n",
       "  26325: 14,\n",
       "  26326: 14,\n",
       "  26327: 14,\n",
       "  26328: 14,\n",
       "  26329: 14,\n",
       "  26330: 14,\n",
       "  26331: 14,\n",
       "  26332: 14,\n",
       "  26333: 14,\n",
       "  26334: 14,\n",
       "  26335: 14,\n",
       "  26336: 14,\n",
       "  26337: 14,\n",
       "  26338: 14,\n",
       "  26339: 14,\n",
       "  26340: 14,\n",
       "  26341: 14,\n",
       "  15250: 14,\n",
       "  26342: 14,\n",
       "  26343: 14,\n",
       "  26344: 14,\n",
       "  26345: 14,\n",
       "  26346: 14,\n",
       "  26347: 14,\n",
       "  22279: 14,\n",
       "  26348: 14,\n",
       "  26349: 14,\n",
       "  26350: 14,\n",
       "  26351: 14,\n",
       "  26352: 14,\n",
       "  26353: 14,\n",
       "  26354: 14,\n",
       "  26355: 14,\n",
       "  26356: 14,\n",
       "  26357: 14,\n",
       "  26358: 14,\n",
       "  26359: 14,\n",
       "  18798: 14,\n",
       "  26360: 14,\n",
       "  15249: 14,\n",
       "  26361: 14,\n",
       "  26362: 14,\n",
       "  26363: 14,\n",
       "  11025: 14,\n",
       "  4869: 14,\n",
       "  26364: 2,\n",
       "  26365: 6,\n",
       "  26366: 6,\n",
       "  26367: 6,\n",
       "  26368: 18,\n",
       "  26369: 2,\n",
       "  26370: 6,\n",
       "  26371: 6,\n",
       "  26372: 2,\n",
       "  26373: 6,\n",
       "  26374: 18,\n",
       "  26375: 2,\n",
       "  26376: 18,\n",
       "  25070: 1,\n",
       "  26377: 2,\n",
       "  26378: 2,\n",
       "  26379: 6,\n",
       "  26380: 18,\n",
       "  26381: 18,\n",
       "  26382: 2,\n",
       "  26383: 2,\n",
       "  26384: 18,\n",
       "  26385: 2,\n",
       "  26386: 6,\n",
       "  26387: 18,\n",
       "  26388: 2,\n",
       "  26389: 6,\n",
       "  26390: 2,\n",
       "  26391: 18,\n",
       "  26392: 2,\n",
       "  26393: 2,\n",
       "  26394: 14,\n",
       "  26395: 14,\n",
       "  26396: 14,\n",
       "  26397: 14,\n",
       "  26398: 14,\n",
       "  26399: 14,\n",
       "  26400: 14,\n",
       "  26401: 14,\n",
       "  26402: 14,\n",
       "  26403: 14,\n",
       "  26404: 14,\n",
       "  26405: 14,\n",
       "  26406: 14,\n",
       "  26407: 14,\n",
       "  26408: 14,\n",
       "  26409: 14,\n",
       "  26410: 14,\n",
       "  26411: 14,\n",
       "  26412: 14,\n",
       "  26413: 14,\n",
       "  26414: 14,\n",
       "  26415: 14,\n",
       "  26416: 14,\n",
       "  26417: 14,\n",
       "  23287: 14,\n",
       "  26418: 14,\n",
       "  26419: 14,\n",
       "  26420: 14,\n",
       "  26421: 14,\n",
       "  9742: 14,\n",
       "  26422: 14,\n",
       "  26423: 14,\n",
       "  26424: 14,\n",
       "  26425: 14,\n",
       "  26426: 14,\n",
       "  26427: 14,\n",
       "  26428: 14,\n",
       "  26429: 14,\n",
       "  26430: 14,\n",
       "  26431: 14,\n",
       "  26432: 14,\n",
       "  26433: 14,\n",
       "  26434: 14,\n",
       "  26435: 14,\n",
       "  26436: 14,\n",
       "  26437: 14,\n",
       "  26438: 14,\n",
       "  26439: 14,\n",
       "  26440: 14,\n",
       "  26441: 14,\n",
       "  26442: 2,\n",
       "  26443: 18,\n",
       "  25071: 1,\n",
       "  26444: 14,\n",
       "  26445: 14,\n",
       "  26446: 14,\n",
       "  26447: 14,\n",
       "  26448: 14,\n",
       "  26449: 14,\n",
       "  26450: 14,\n",
       "  26451: 14,\n",
       "  26452: 14,\n",
       "  26453: 14,\n",
       "  26454: 14,\n",
       "  26455: 14,\n",
       "  26456: 14,\n",
       "  26457: 14,\n",
       "  26458: 14,\n",
       "  26459: 14,\n",
       "  26460: 14,\n",
       "  19954: 14,\n",
       "  26461: 14,\n",
       "  26462: 14,\n",
       "  26463: 14,\n",
       "  26464: 14,\n",
       "  26465: 14,\n",
       "  26466: 14,\n",
       "  26467: 14,\n",
       "  26468: 14,\n",
       "  26469: 14,\n",
       "  26470: 14,\n",
       "  26471: 2,\n",
       "  26472: 18,\n",
       "  26473: 18,\n",
       "  26474: 2,\n",
       "  26475: 6,\n",
       "  26476: 18,\n",
       "  26477: 2,\n",
       "  26478: 6,\n",
       "  26479: 18,\n",
       "  26480: 2,\n",
       "  26481: 18,\n",
       "  24490: 1,\n",
       "  26482: 2,\n",
       "  26483: 18,\n",
       "  26484: 18,\n",
       "  26485: 6,\n",
       "  26486: 2,\n",
       "  26487: 18,\n",
       "  26488: 2,\n",
       "  26489: 6,\n",
       "  26490: 2,\n",
       "  26491: 2,\n",
       "  26492: 2,\n",
       "  26493: 18,\n",
       "  26494: 18,\n",
       "  26495: 18,\n",
       "  26496: 2,\n",
       "  26497: 6,\n",
       "  26498: 18,\n",
       "  26499: 2,\n",
       "  26500: 6,\n",
       "  26501: 2,\n",
       "  26502: 18,\n",
       "  26503: 1,\n",
       "  26504: 2,\n",
       "  26505: 18,\n",
       "  26506: 2,\n",
       "  26507: 18,\n",
       "  26508: 2,\n",
       "  26509: 6,\n",
       "  26510: 18,\n",
       "  26511: 2,\n",
       "  26512: 6,\n",
       "  26513: 18,\n",
       "  26514: 2,\n",
       "  26515: 18,\n",
       "  26516: 2,\n",
       "  26517: 1,\n",
       "  26518: 18,\n",
       "  26519: 2,\n",
       "  26520: 18,\n",
       "  26521: 2,\n",
       "  26522: 6,\n",
       "  26523: 18,\n",
       "  26524: 2,\n",
       "  26525: 6,\n",
       "  26526: 18,\n",
       "  26527: 2,\n",
       "  26528: 18,\n",
       "  26529: 2,\n",
       "  24492: 1,\n",
       "  26530: 18,\n",
       "  26531: 2,\n",
       "  24280: 14,\n",
       "  24279: 14,\n",
       "  24278: 14,\n",
       "  23677: 14,\n",
       "  20705: 14,\n",
       "  24283: 14,\n",
       "  24282: 14,\n",
       "  24281: 14,\n",
       "  26532: 18,\n",
       "  26533: 2,\n",
       "  26534: 6,\n",
       "  26535: 6,\n",
       "  26536: 2,\n",
       "  26537: 18,\n",
       "  26538: 2,\n",
       "  26539: 18,\n",
       "  26540: 2,\n",
       "  26541: 1,\n",
       "  26542: 18,\n",
       "  26543: 2,\n",
       "  26544: 18,\n",
       "  26545: 2,\n",
       "  26546: 6,\n",
       "  26547: 2,\n",
       "  26548: 18,\n",
       "  26549: 6,\n",
       "  26550: 18,\n",
       "  26551: 2,\n",
       "  26552: 2,\n",
       "  26553: 1,\n",
       "  26554: 18,\n",
       "  23588: 18,\n",
       "  26555: 2,\n",
       "  26556: 6,\n",
       "  26557: 2,\n",
       "  26558: 2,\n",
       "  26559: 18,\n",
       "  26560: 6,\n",
       "  26561: 2,\n",
       "  26562: 2,\n",
       "  26563: 2,\n",
       "  22995: 1,\n",
       "  23589: 18,\n",
       "  26564: 18,\n",
       "  23618: 18,\n",
       "  26565: 6,\n",
       "  26566: 2,\n",
       "  26567: 6,\n",
       "  26568: 2,\n",
       "  26569: 2,\n",
       "  26570: 2,\n",
       "  26571: 2,\n",
       "  24491: 1,\n",
       "  23590: 18,\n",
       "  26572: 18,\n",
       "  23593: 18,\n",
       "  26573: 6,\n",
       "  23617: 18,\n",
       "  26574: 2,\n",
       "  24104: 6,\n",
       "  26575: 2,\n",
       "  26576: 2,\n",
       "  26577: 1,\n",
       "  23619: 18,\n",
       "  26578: 2,\n",
       "  23620: 18,\n",
       "  23591: 18,\n",
       "  24105: 6,\n",
       "  26579: 18,\n",
       "  24106: 6,\n",
       "  26580: 2,\n",
       "  26581: 2,\n",
       "  26582: 2,\n",
       "  26583: 1,\n",
       "  26584: 18,\n",
       "  26585: 2,\n",
       "  23592: 18,\n",
       "  26586: 18,\n",
       "  24107: 6,\n",
       "  26587: 2,\n",
       "  26588: 18,\n",
       "  24108: 6,\n",
       "  26589: 2,\n",
       "  26590: 2,\n",
       "  26591: 1,\n",
       "  26592: 18,\n",
       "  23594: 18,\n",
       "  26593: 18,\n",
       "  24109: 6,\n",
       "  26594: 2,\n",
       "  26595: 18,\n",
       "  24110: 6,\n",
       "  26596: 2,\n",
       "  26597: 18,\n",
       "  24111: 6,\n",
       "  23595: 18,\n",
       "  26598: 18,\n",
       "  26599: 18,\n",
       "  26600: 18,\n",
       "  24112: 6,\n",
       "  24113: 6,\n",
       "  23596: 18,\n",
       "  23597: 18,\n",
       "  23598: 18,\n",
       "  23599: 18,\n",
       "  24114: 6,\n",
       "  26601: 18,\n",
       "  26602: 6,\n",
       "  26603: 18,\n",
       "  26604: 14,\n",
       "  20708: 14,\n",
       "  26605: 14,\n",
       "  19751: 14,\n",
       "  21736: 14,\n",
       "  24693: 2,\n",
       "  26606: 6,\n",
       "  26607: 18,\n",
       "  26608: 18,\n",
       "  23600: 18,\n",
       "  26609: 6,\n",
       "  26610: 18,\n",
       "  26611: 14,\n",
       "  23601: 18,\n",
       "  26612: 6,\n",
       "  26613: 18,\n",
       "  26614: 18,\n",
       "  26615: 18,\n",
       "  26616: 14,\n",
       "  25001: 2,\n",
       "  24996: 2,\n",
       "  24993: 2,\n",
       "  24949: 2,\n",
       "  26617: 2,\n",
       "  26618: 2,\n",
       "  26619: 2,\n",
       "  26620: 2,\n",
       "  26621: 2,\n",
       "  12334: 2,\n",
       "  12333: 2,\n",
       "  8061: 2,\n",
       "  26622: 2,\n",
       "  26623: 2,\n",
       "  26624: 2,\n",
       "  24950: 2,\n",
       "  26625: 2,\n",
       "  26626: 2,\n",
       "  26627: 2,\n",
       "  26628: 2,\n",
       "  26629: 2,\n",
       "  26630: 2,\n",
       "  26631: 2,\n",
       "  26632: 2,\n",
       "  24994: 2,\n",
       "  26633: 2,\n",
       "  26634: 2,\n",
       "  26635: 2,\n",
       "  26636: 2,\n",
       "  26637: 2,\n",
       "  26638: 2,\n",
       "  26639: 2,\n",
       "  26640: 2,\n",
       "  26641: 2,\n",
       "  26642: 2,\n",
       "  26643: 2,\n",
       "  26644: 2,\n",
       "  26645: 2,\n",
       "  26646: 2,\n",
       "  26647: 2,\n",
       "  26648: 2,\n",
       "  26649: 2,\n",
       "  26650: 2,\n",
       "  26651: 2,\n",
       "  26652: 2,\n",
       "  26653: 2,\n",
       "  26654: 2,\n",
       "  26655: 2,\n",
       "  26656: 2,\n",
       "  26657: 2,\n",
       "  26658: 2,\n",
       "  26659: 2,\n",
       "  26660: 6,\n",
       "  26661: 18,\n",
       "  23602: 18,\n",
       "  26662: 18,\n",
       "  26663: 6,\n",
       "  26664: 18,\n",
       "  24790: 14,\n",
       "  26665: 18,\n",
       "  23603: 18,\n",
       "  26666: 6,\n",
       "  26667: 18,\n",
       "  26668: 6,\n",
       "  26669: 18,\n",
       "  26670: 6,\n",
       "  23604: 18,\n",
       "  26671: 18,\n",
       "  23605: 18,\n",
       "  26672: 18,\n",
       "  26673: 6,\n",
       "  26674: 6,\n",
       "  23606: 18,\n",
       "  26675: 18,\n",
       "  26676: 18,\n",
       "  26677: 18,\n",
       "  23607: 18,\n",
       "  26678: 6,\n",
       "  26679: 18,\n",
       "  26680: 6,\n",
       "  26681: 18,\n",
       "  26682: 18,\n",
       "  23608: 18,\n",
       "  26683: 18,\n",
       "  26684: 18,\n",
       "  23609: 18,\n",
       "  26685: 18,\n",
       "  26686: 6,\n",
       "  26687: 18,\n",
       "  26688: 6,\n",
       "  26689: 18,\n",
       "  23610: 18,\n",
       "  26690: 18,\n",
       "  182: 14,\n",
       "  4791: 14,\n",
       "  4790: 14,\n",
       "  4047: 14,\n",
       "  2630: 14,\n",
       "  2629: 14,\n",
       "  3665: 14,\n",
       "  2174: 14,\n",
       "  3664: 14,\n",
       "  3663: 14,\n",
       "  357: 14,\n",
       "  356: 14,\n",
       "  4023: 14,\n",
       "  5337: 14,\n",
       "  5336: 14,\n",
       "  5335: 14,\n",
       "  5340: 14,\n",
       "  5339: 14,\n",
       "  5338: 14,\n",
       "  4036: 14,\n",
       "  4022: 14,\n",
       "  5334: 14,\n",
       "  5333: 14,\n",
       "  5332: 14,\n",
       "  4051: 14,\n",
       "  4050: 14,\n",
       "  4049: 14,\n",
       "  4048: 14,\n",
       "  5331: 14,\n",
       "  5330: 14,\n",
       "  5329: 14,\n",
       "  5328: 14,\n",
       "  5327: 14,\n",
       "  5326: 14,\n",
       "  5325: 14,\n",
       "  4929: 14,\n",
       "  4928: 14,\n",
       "  4927: 14,\n",
       "  4926: 14,\n",
       "  4925: 14,\n",
       "  4924: 14,\n",
       "  4923: 14,\n",
       "  363: 14,\n",
       "  4922: 14,\n",
       "  4921: 14,\n",
       "  4920: 14,\n",
       "  4919: 14,\n",
       "  4793: 14,\n",
       "  4792: 14,\n",
       "  4038: 14,\n",
       "  2456: 14,\n",
       "  4037: 14,\n",
       "  26691: 2,\n",
       "  26692: 2,\n",
       "  26693: 2,\n",
       "  26694: 2,\n",
       "  26695: 2,\n",
       "  26696: 2,\n",
       "  26697: 2,\n",
       "  22992: 2,\n",
       "  22991: 2,\n",
       "  22990: 2,\n",
       "  26698: 6,\n",
       "  26699: 18,\n",
       "  26700: 2,\n",
       "  1900: 14,\n",
       "  1903: 14,\n",
       "  1902: 14,\n",
       "  1901: 14,\n",
       "  3544: 14,\n",
       "  4011: 14,\n",
       "  4298: 14,\n",
       "  4012: 14,\n",
       "  4008: 14,\n",
       "  4009: 14,\n",
       "  1909: 14,\n",
       "  4721: 14,\n",
       "  4039: 14,\n",
       "  3975: 14,\n",
       "  2933: 14,\n",
       "  2932: 14,\n",
       "  3336: 14,\n",
       "  3335: 14,\n",
       "  3334: 14,\n",
       "  362: 14,\n",
       "  177: 14,\n",
       "  828: 14,\n",
       "  1379: 14,\n",
       "  2129: 14,\n",
       "  740: 14,\n",
       "  737: 14,\n",
       "  1584: 5,\n",
       "  3696: 5,\n",
       "  3670: 5,\n",
       "  981: 5,\n",
       "  3669: 5,\n",
       "  1911: 5,\n",
       "  1299: 5,\n",
       "  489: 5,\n",
       "  186: 5,\n",
       "  3697: 5,\n",
       "  1910: 5,\n",
       "  3698: 5,\n",
       "  3695: 5,\n",
       "  23616: 18,\n",
       "  26701: 6,\n",
       "  26702: 18,\n",
       "  26703: 18,\n",
       "  26704: 6,\n",
       "  26705: 2,\n",
       "  26706: 18,\n",
       "  75: 2,\n",
       "  133: 2,\n",
       "  74: 2,\n",
       "  6370: 2,\n",
       "  77: 2,\n",
       "  82: 2,\n",
       "  ...}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_dict = tag.set_index('album_id').to_dict()\n",
    "tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f1aa703",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = cluster_df.set_index('album_id').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4273131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 특징 정보의 속성을 저장 \n",
    "cfg.n_genre_small = meta_df['genre_small'].nunique()\n",
    "cfg.n_genre_mid = meta_df['genre_mid'].nunique()\n",
    "cfg.n_genre_large = meta_df['genre_large'].nunique()\n",
    "cfg.n_cast_1 = meta_df['cast_1'].nunique()\n",
    "cfg.n_cast_2 = meta_df['cast_2'].nunique()\n",
    "cfg.n_cast_3 = meta_df['cast_3'].nunique()\n",
    "cfg.n_cast_4 = meta_df['cast_4'].nunique()\n",
    "cfg.n_cast_5 = meta_df['cast_5'].nunique()\n",
    "cfg.n_cast_6 = meta_df['cast_6'].nunique()\n",
    "cfg.n_cast_7 = meta_df['cast_7'].nunique()\n",
    "cfg.tag = tag['tag'].nunique()\n",
    "cfg.cluster5 = cluster_df['clus5'].nunique()\n",
    "cfg.cluster8 = cluster_df['clus8'].nunique()\n",
    "cfg.cluster12 = cluster_df['clus12'].nunique()\n",
    "\n",
    "cfg.n_continuous_feats = 2 # 연속형 feature는 나이 + watch 변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4abb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    \"\"\"Neural Matrix Factorization Model\n",
    "        참고 문헌 : https://arxiv.org/abs/1708.05031\n",
    "\n",
    "    예시 :\n",
    "        model = NeuMF(cfg) \n",
    "        output = model.forward(user_ids, item_ids, [feat0, feat1]) \n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            cfg : config 파일로 네트워크 생성에 필요한 정보들을 담고 있음 \n",
    "        \"\"\"\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.n_users = cfg.n_users\n",
    "        self.n_items = cfg.n_items\n",
    "        self.emb_dim = cfg.emb_dim\n",
    "        self.layer_dim = cfg.layer_dim\n",
    "#         self.layer_dim2 = cfg.layer_dim2\n",
    "        self.n_continuous_feats = cfg.n_continuous_feats\n",
    "        self.n_genre_mid = cfg.n_genre_mid\n",
    "#         self.n_genre_large = cfg.n_genre_large\n",
    "        self.n_pr_interest_1 = cfg.n_pr_interest_keyword_1    \n",
    "        self.n_ch_interest_1 = cfg.n_ch_interest_keyword_1 \n",
    "#         self.n_pr_interest_2 = cfg.n_pr_interest_keyword_2    \n",
    "#         self.n_ch_interest_2 = cfg.n_ch_interest_keyword_2 \n",
    "#         self.n_pr_interest_3 = cfg.n_pr_interest_keyword_3    \n",
    "#         self.n_ch_interest_3 = cfg.n_ch_interest_keyword_3 \n",
    "        self.dropout = cfg.dropout\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Neural Matrix Factorization Model 생성\n",
    "            구현된 모습은 위의 그림을 참고 \n",
    "        \"\"\"\n",
    "        self.user_embedding_mf = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)  #256\n",
    "        self.item_embedding_mf = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "        \n",
    "        \n",
    "        self.sex_embedding = nn.Embedding(num_embeddings=2, embedding_dim=1)\n",
    "        self.genre_mid_embeddig = nn.Embedding(num_embeddings=self.n_genre_mid, embedding_dim=self.n_genre_mid//2)\n",
    "#         self.genre_large_embeddig = nn.Embedding(num_embeddings=self.n_genre_large, embedding_dim=self.n_genre_large//2)\n",
    "        \n",
    "        \n",
    "        self.pr_interest_1_embedding = nn.Embedding(num_embeddings=self.n_pr_interest_1, embedding_dim=self.n_pr_interest_1//2)\n",
    "        self.ch_interest_1_embedding = nn.Embedding(num_embeddings=self.n_ch_interest_1, embedding_dim=self.n_ch_interest_1//2)\n",
    "#         self.pr_interest_2_embedding = nn.Embedding(num_embeddings=self.n_pr_interest_2, embedding_dim=self.n_pr_interest_2//2)\n",
    "#         self.ch_interest_2_embedding = nn.Embedding(num_embeddings=self.n_ch_interest_2, embedding_dim=self.n_ch_interest_2//2)\n",
    "#         self.pr_interest_3_embedding = nn.Embedding(num_embeddings=self.n_pr_interest_3, embedding_dim=self.n_pr_interest_3//2)\n",
    "#         self.ch_interest_3_embedding = nn.Embedding(num_embeddings=self.n_ch_interest_3, embedding_dim=self.n_ch_interest_3//2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Linear(2*self.emb_dim +self.n_genre_mid//2 + self.n_pr_interest_1//2 + self.n_ch_interest_1//2+\n",
    "#                       self.n_pr_interest_2//2 + self.n_ch_interest_2//2+self.n_pr_interest_3//2 + self.n_ch_interest_3//2+\n",
    "                      self.n_continuous_feats +1, self.layer_dim),\n",
    "            nn.BatchNorm1d(self.layer_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.dropout), \n",
    "            nn.Linear(self.layer_dim, self.layer_dim//2),\n",
    "            nn.BatchNorm1d(self.layer_dim//2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=self.dropout),\n",
    "#             nn.Linear(self.layer_dim2, self.layer_dim2//2), \n",
    "#             nn.ReLU(), \n",
    "#             nn.Dropout(p=self.dropout),\n",
    "            \n",
    "        )\n",
    "        self.affine_output = nn.Linear(self.layer_dim//2 + self.emb_dim, 1)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            normal_(module.weight.data, mean=0.0, std=0.01)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            normal_(module.weight.data, 0, 0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices, feats):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            user_indices : 유저의 인덱스 정보 \n",
    "                ex) tensor([ 3100,  3100,  ..., 14195, 14195])\n",
    "            item_indices : 아이템의 인덱스 정보\n",
    "                ex) tensor([   50,    65,   ..., 14960, 11527])\n",
    "            feats : 특징 정보 \n",
    "        Returns: \n",
    "            output : 유저-아이템 쌍에 대한 추천 결과 \n",
    "                ex) tensor([  9.4966,  22.0261, ..., -19.3535, -23.0212])\n",
    "        \"\"\"\n",
    "        user_embedding_mf = self.user_embedding_mf(user_indices)\n",
    "#         print(user_embedding_mf.shape)\n",
    "        item_embedding_mf = self.item_embedding_mf(item_indices)\n",
    "#         print(item_embedding_mf.shape)\n",
    "        mf_output = torch.mul(user_embedding_mf, item_embedding_mf)  # element wise\n",
    "        \n",
    "        user_embedding_mlp = self.user_embedding_mlp(user_indices)\n",
    "        item_embedding_mlp = self.item_embedding_mlp(item_indices)\n",
    "        genre_mid_embedding_mlp = self.genre_mid_embeddig(feats[5])\n",
    "#         genre_large_embedding_mlp = self.genre_large_embeddig(feats[4])\n",
    "        pr_interest_1_embedding_mlp = self.pr_interest_1_embedding(feats[3])\n",
    "        ch_interest_1_embedding_mlp = self.ch_interest_1_embedding(feats[4])\n",
    "#         pr_interest_2_embedding_mlp = self.pr_interest_2_embedding(feats[2])\n",
    "#         ch_interest_2_embedding_mlp = self.ch_interest_2_embedding(feats[3])\n",
    "#         pr_interest_3_embedding_mlp = self.pr_interest_3_embedding(feats[2])\n",
    "#         ch_interest_3_embedding_mlp = self.ch_interest_3_embedding(feats[3])\n",
    "        \n",
    "        sex_embedding_mlp = self.sex_embedding(feats[2])\n",
    "        input_feature = torch.cat((user_embedding_mlp, item_embedding_mlp,genre_mid_embedding_mlp,\n",
    "                                   pr_interest_1_embedding_mlp,ch_interest_1_embedding_mlp,\n",
    "#                                    pr_interest_2_embedding_mlp,ch_interest_2_embedding_mlp,\n",
    "#                                    pr_interest_3_embedding_mlp,ch_interest_3_embedding_mlp,\n",
    "                                   sex_embedding_mlp,feats[0].unsqueeze(1),feats[1].unsqueeze(1)), -1)\n",
    "        mlp_output = self.mlp_layers(input_feature)\n",
    "        \n",
    "        output = torch.cat([mlp_output, mf_output], dim=-1)\n",
    "        output = self.affine_output(output).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e577a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_UIdataset(train, neg_ratio):\n",
    "    \n",
    "    UIdataset = {}\n",
    "    for user_id, items_by_user in enumerate(train):\n",
    "        UIdataset[user_id] = []\n",
    "        # positive 샘플 계산 \n",
    "        pos_item_ids = np.where(items_by_user > 0.5)[0]\n",
    "        num_pos_samples = len(pos_item_ids)\n",
    "\n",
    "        # negative 샘플 계산 (random negative sampling) \n",
    "        num_neg_samples = neg_ratio * num_pos_samples\n",
    "        neg_items = np.where(items_by_user < 0.5)[0]\n",
    "        neg_item_ids = np.random.choice(neg_items, min(num_neg_samples, len(neg_items)), replace=False)\n",
    "        UIdataset[user_id].append(np.concatenate([pos_item_ids, neg_item_ids]))\n",
    "        \n",
    "        # feature 'age' \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(user_features['age'][user_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # feature 'watch' \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]):\n",
    "            if (user_id, item_id) in watch_dict.keys():\n",
    "                features.append(watch_dict[(user_id, item_id)])\n",
    "            else:\n",
    "                features.append(0)\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # feature 'sex' \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(user_features['sex'][user_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "\n",
    "        \n",
    "        # feature 'genre_mid'\n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(item_features['genre_mid'][item_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # feature 'tag'\n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(tag_dict['tag'][item_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # feature 'cluster8'\n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(cluster_dict['clus8'][item_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        \n",
    "        # label 저장  \n",
    "        pos_labels = np.ones(len(pos_item_ids))\n",
    "        neg_labels = np.zeros(len(neg_item_ids))\n",
    "        UIdataset[user_id].append(np.concatenate([pos_labels, neg_labels]))\n",
    "\n",
    "    return UIdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4812cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UIdataset = make_UIdataset(train, neg_ratio=cfg.neg_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e41cc702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   16,    17,    18, ..., 18650, 21729,  3569]),\n",
       " array([5, 5, 5, ..., 5, 5, 5]),\n",
       " array([0.99047619, 1.        , 0.98529412, ..., 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " array([4, 4, 4, ..., 3, 5, 5]),\n",
       " array([22, 22, 22, ...,  5,  2,  2]),\n",
       " array([4, 4, 4, ..., 4, 1, 1]),\n",
       " array([1., 1., 1., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UIdataset[3]\n",
    "# 1. 나이\n",
    "# 2. watching2\n",
    "# 3. 성별\n",
    "# 4. genre\n",
    "# 5. tag\n",
    "# 6. cluster8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62798928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batchdata(user_indices, batch_idx, batch_size):\n",
    "    \n",
    "    batch_user_indices = user_indices[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "    batch_user_ids = []\n",
    "    batch_item_ids = []\n",
    "    batch_feat0 = []\n",
    "    batch_feat1 = []\n",
    "    batch_feat2 = []\n",
    "    batch_feat3 = []\n",
    "    batch_feat4 = []\n",
    "    batch_feat5 = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for user_id in batch_user_indices:\n",
    "        \n",
    "        item_ids = UIdataset[user_id][0] # 시청 아이템 index\n",
    "        \n",
    "        feat0 = UIdataset[user_id][1] # 나이\n",
    "        feat1 = UIdataset[user_id][2] # 시청시간\n",
    "        feat2 = UIdataset[user_id][3] # 성별\n",
    "        \n",
    "        feat3 = UIdataset[user_id][4] # 장르\n",
    "        feat4 = UIdataset[user_id][5] # 태그\n",
    "        feat5 = UIdataset[user_id][6] # cluster8\n",
    "        \n",
    "        labels = UIdataset[user_id][7] # 평점\n",
    "        \n",
    "        user_ids = np.full(len(item_ids), user_id)\n",
    "        batch_user_ids.extend(user_ids.tolist())\n",
    "        batch_item_ids.extend(item_ids.tolist())\n",
    "        \n",
    "        batch_feat0.extend(feat0.tolist())\n",
    "        batch_feat1.extend(feat1.tolist())\n",
    "        batch_feat2.extend(feat2.tolist())\n",
    "        batch_feat3.extend(feat3.tolist())\n",
    "        batch_feat4.extend(feat4.tolist())\n",
    "        batch_feat5.extend(feat5.tolist())\n",
    "        \n",
    "        batch_labels.extend(labels.tolist())\n",
    "        \n",
    "    return batch_user_ids, batch_item_ids, batch_feat0, batch_feat1, batch_feat2, batch_feat3, batch_feat4, batch_feat5, batch_labels\n",
    "\n",
    "def update_avg(curr_avg, val, idx):\n",
    "    \"\"\" 현재 epoch 까지의 평균 값을 계산 \n",
    "    \"\"\"\n",
    "    return (curr_avg * idx + val) / (idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7297a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(cfg, model, optimizer, criterion): \n",
    "    model.train()\n",
    "    curr_loss_avg = 0.0\n",
    "\n",
    "    user_indices = np.arange(cfg.n_users)\n",
    "    np.random.RandomState(cfg.epoch).shuffle(user_indices)\n",
    "    batch_num = int(len(user_indices) / cfg.batch_size) + 1\n",
    "    bar = tqdm(range(batch_num), leave=False)\n",
    "    \n",
    "    for step, batch_idx in enumerate(bar):\n",
    "        user_ids, item_ids, feat0, feat1, feat2, feat3, feat4, feat5, labels = make_batchdata(user_indices, batch_idx, cfg.batch_size)\n",
    "        \n",
    "        # 배치 사용자 단위로 학습\n",
    "        user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "        item_ids = torch.LongTensor(item_ids).to(cfg.device)\n",
    "        \n",
    "        feat0 = torch.FloatTensor(feat0).to(cfg.device) # 나이: 연속형 -> FloatTensor\n",
    "        feat1 = torch.FloatTensor(feat1).to(cfg.device) # 시청시간: 연속형 -> FloatTensor\n",
    "        \n",
    "        # Long Tensor\n",
    "        feat2 = torch.LongTensor(feat2).to(cfg.device) # 성별\n",
    "        \n",
    "        feat3 = torch.LongTensor(feat3).to(cfg.device) # genre\n",
    "        feat4 = torch.LongTensor(feat4).to(cfg.device) # tag\n",
    "        feat5 = torch.LongTensor(feat5).to(cfg.device) # cluster8\n",
    "        \n",
    "        labels = torch.FloatTensor(labels).to(cfg.device)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # grad 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 forward\n",
    "        output = model.forward(user_ids, item_ids, [feat0, feat1, feat2, feat3, feat4, feat5])\n",
    "        output = output.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 최적화\n",
    "        optimizer.step()    \n",
    "        if torch.isnan(loss):\n",
    "            print('Loss NAN. Train finish.')\n",
    "            break\n",
    "        curr_loss_avg = update_avg(curr_loss_avg, loss, step)\n",
    "        \n",
    "        msg = f\"epoch: {cfg.epoch}, \"\n",
    "        msg += f\"loss: {curr_loss_avg.item():.5f}, \"\n",
    "        msg += f\"lr: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        bar.set_description(msg)\n",
    "    rets = {'losses': np.around(curr_loss_avg.item(), 5)}\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c03f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(cfg, model, data, mode='valid'):\n",
    "    pred_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    query_user_ids = data['profile_id'].unique() # 추론할 모든 user array 집합\n",
    "    \n",
    "    full_item_ids = np.array([c for c in range(cfg.n_items)]) # 추론할 모든 item array 집합\n",
    "    full_item_ids_feat3 = [item_features['genre_mid'][c] for c in full_item_ids]\n",
    "    full_item_ids_feat4 = [tag_dict['tag'][c] for c in full_item_ids]\n",
    "    full_item_ids_feat5 = [cluster_dict['clus8'][c] for c in full_item_ids] # cluster8\n",
    "    \n",
    "    for user_id in tqdm(query_user_ids):\n",
    "        with torch.no_grad():\n",
    "            user_ids = np.full(cfg.n_items, user_id)\n",
    "            \n",
    "            user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "            item_ids = torch.LongTensor(full_item_ids).to(cfg.device)\n",
    "            \n",
    "            # 사용자 feature\n",
    "            feat0 = np.full(cfg.n_items, user_features['age'][user_id]) # age\n",
    "            feat0 = torch.FloatTensor(feat0).to(cfg.device)\n",
    "            \n",
    "            # feature1 'watch'\n",
    "            user_item_watch=[]\n",
    "            for item_id in full_item_ids:\n",
    "                if (user_id, item_id) in watch_dict.keys():\n",
    "                    user_item_watch.append(watch_dict[(user_id, item_id)])\n",
    "                else:\n",
    "                    user_item_watch.append(0)\n",
    "            \n",
    "            feat1 = np.array(user_item_watch)\n",
    "            feat1 = torch.FloatTensor(feat1).to(cfg.device)\n",
    "            \n",
    "            feat2 = np.full(cfg.n_items, user_features['sex'][user_id]) # sex\n",
    "            feat2 = torch.LongTensor(feat2).to(cfg.device)\n",
    "            \n",
    "            # 아이템 feature\n",
    "            feat3 = torch.LongTensor(full_item_ids_feat3).to(cfg.device)\n",
    "            feat4 = torch.LongTensor(full_item_ids_feat4).to(cfg.device)\n",
    "            feat5 = torch.LongTensor(full_item_ids_feat5).to(cfg.device)\n",
    "            \n",
    "            eval_output = model.forward(user_ids, item_ids, [feat0, feat1, feat2, feat3, feat4, feat5]).detach().cpu().numpy()\n",
    "            pred_u_score = eval_output.reshape(-1)   \n",
    "        \n",
    "        pred_u_idx = np.argsort(pred_u_score)[::-1]\n",
    "        pred_u = full_item_ids[pred_u_idx]\n",
    "        pred_list.append(list(pred_u[:cfg.top_k]))\n",
    "        \n",
    "    pred = pd.DataFrame()\n",
    "    pred['profile_id'] = query_user_ids\n",
    "    pred['predicted_list'] = pred_list\n",
    "    \n",
    "    # 모델 성능 확인 \n",
    "    if mode == 'valid':\n",
    "        rets = evaluation(data, pred)\n",
    "        return rets, pred\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0c9913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallk(actual, predicted, k = 25):\n",
    "    set_actual = set(actual)\n",
    "    recall_k = len(set_actual & set(predicted[:k])) / min(k, len(set_actual))\n",
    "    return recall_k\n",
    "\n",
    "def unique(sequence):\n",
    "    # preserves order\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "def ndcgk(actual, predicted, k = 25):\n",
    "    set_actual = set(actual)\n",
    "    idcg = sum([1.0 / np.log(i + 2) for i in range(min(k, len(set_actual)))]) \n",
    "    dcg = 0.0\n",
    "    unique_predicted = unique(predicted[:k])\n",
    "    for i, r in enumerate(unique_predicted):\n",
    "        if r in set_actual:\n",
    "            dcg += 1.0 / np.log(i + 2)\n",
    "    ndcg_k = dcg / idcg\n",
    "    return ndcg_k\n",
    "\n",
    "def evaluation(gt, pred):\n",
    "    \n",
    "    gt = gt.groupby('profile_id')['album_id'].unique().to_frame().reset_index()\n",
    "    gt.columns = ['profile_id', 'actual_list']\n",
    "\n",
    "    evaluated_data = pd.merge(pred, gt, how = 'left', on = 'profile_id')\n",
    "\n",
    "    evaluated_data['Recall@25'] = evaluated_data.apply(lambda x: recallk(x.actual_list, x.predicted_list), axis=1)\n",
    "    evaluated_data['NDCG@25'] = evaluated_data.apply(lambda x: ndcgk(x.actual_list, x.predicted_list), axis=1)\n",
    "\n",
    "    recall = evaluated_data['Recall@25'].mean()\n",
    "    ndcg = evaluated_data['NDCG@25'] .mean()\n",
    "    coverage = (evaluated_data['predicted_list'].apply(lambda x: x[:cfg.top_k]).explode().nunique())/meta_df.index.nunique()\n",
    "\n",
    "    score = 0.75*recall + 0.25*ndcg\n",
    "    rets = {\"recall\" :recall, \n",
    "            \"ndcg\" :ndcg, \n",
    "            \"coverage\" :coverage, \n",
    "            \"score\" :score}\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddf2a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 생성 및 optimizer, loss 함수 설정 \n",
    "model = NeuMF(cfg).to(cfg.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.reg_lambda)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.91)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "716c5f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b67240be3b64d9dbaee7183dc0e4d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch,Train Loss,Valid Recall@25,Valid NDCG@25,Valid Coverage,Valid Score\n",
      "00  13258.392580  0.591660  0.499085  0.248627  0.568516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7d7532507743429b17a716401cc6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01  4079.033690  0.615045  0.509248  0.262671  0.588596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c654ae1b3cf4437959e6535de510e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02  3276.695560  0.631408  0.507447  0.258658  0.600418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec3a4f915064a949da42ec6dfc26644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03  2464.078120  0.649035  0.508765  0.261417  0.613967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291b560f0a85408882fbd41b53bff68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04  1714.737430  0.645896  0.495131  0.273254  0.608205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1343e0df6f444c42b76b3d2c4dc3a1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05  1080.913090  0.649040  0.496890  0.294871  0.611003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f645df7bf848eb989ce3b3e90449b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06  675.606690  0.639794  0.482320  0.302545  0.600425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9aac05a8b642bb8923964d1ea58b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07  444.111420  0.643601  0.485914  0.310771  0.604179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b75aba41de41eba990779bf4418b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08  304.613650  0.637845  0.480143  0.307812  0.598420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56d213130ab434283406f5505448126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# cfg.check_epoch 번의 epoch 마다 성능 확인 \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m cfg\u001b[38;5;241m.\u001b[39mcheck_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[0;32m---> 10\u001b[0m     valid_results, _ \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid Recall@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mtop_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: valid_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid Score\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m         }\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 검증 성능 확인 \u001b[39;00m\n",
      "Cell \u001b[0;32mIn [28], line 35\u001b[0m, in \u001b[0;36mvalid_epoch\u001b[0;34m(cfg, model, data, mode)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(user_item_watch) \u001b[38;5;241m==\u001b[39m cfg\u001b[38;5;241m.\u001b[39mn_items, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLENGTH ERROR!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m feat1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(user_item_watch)\n\u001b[0;32m---> 35\u001b[0m feat1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m feat2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(cfg\u001b[38;5;241m.\u001b[39mn_items, user_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m][user_id]) \u001b[38;5;66;03m# sex\u001b[39;00m\n\u001b[1;32m     38\u001b[0m feat2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(feat2)\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_logs = defaultdict(list)\n",
    "best_scores  = 0\n",
    "for epoch in range(cfg.epochs+1):\n",
    "    cfg.epoch = epoch\n",
    "    train_results = train_epoch(cfg, model, optimizer, criterion)\n",
    "    \n",
    "    scheduler.step()\n",
    "    # cfg.check_epoch 번의 epoch 마다 성능 확인 \n",
    "    if epoch % cfg.check_epoch == 0: \n",
    "        valid_results, _ = valid_epoch(cfg, model, valid)\n",
    "\n",
    "        logs = {\n",
    "            'Train Loss': train_results['losses'],\n",
    "            f'Valid Recall@{cfg.top_k}': valid_results['recall'],\n",
    "            f'Valid NDCG@{cfg.top_k}': valid_results['ndcg'],\n",
    "            'Valid Coverage': valid_results['coverage'],\n",
    "            'Valid Score': valid_results['score'],\n",
    "            }\n",
    "\n",
    "        # 검증 성능 확인 \n",
    "        for key, value in logs.items():\n",
    "            total_logs[key].append(value)\n",
    "\n",
    "        if epoch == 0:\n",
    "            print(\"Epoch\", end=\",\")\n",
    "            print(\",\".join(logs.keys()))\n",
    "\n",
    "        print(f\"{epoch:02d}  \", end=\"\")\n",
    "        print(\"  \".join([f\"{v:0.6f}\" for v in logs.values()]))\n",
    "        \n",
    "        # 가장 성능이 좋은 가중치 파일을 저장 \n",
    "        if best_scores <= valid_results['score']: \n",
    "            best_scores = valid_results['score']\n",
    "            torch.save(model.state_dict(), os.path.join(saved_path, 'model(best_scores)_newexp15.pth'))  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d99f5db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(saved_path, 'model(best_scores)_newexp15.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e7a91fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82195a3068bd4e39b61a5e4405ae8134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission_path = os.path.join(data_path, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission = valid_epoch(cfg, model, submission, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "818ce8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(output_path, 'submission_15.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec98342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
